{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pretrained-resnet50.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOrSZqzWTBZ9VI7MK3aCx8Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6ezaxHNURJjM","executionInfo":{"status":"ok","timestamp":1631481128891,"user_tz":-120,"elapsed":1680,"user":{"displayName":"Alberto Baus√° Cano","photoUrl":"","userId":"00514392802027397349"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import time, datetime\n","import matplotlib.pyplot as plt\n","import pickle\n","\n","# constants definition\n","CNN_NAME = 'pretrained_restnet50'\n","EPOCHS = 1\n","NUM_CLASSES = 10\n","BATCH_SIZE_TRAIN = 20\n","BATCH_SIZE_TEST = 128\n","\n","\n","# build the neural net model\n","def build_model():\n","  model = tf.keras.Sequential()\n","  model.add(tf.keras.layers.UpSampling2D((2,2)))\n","  model.add(tf.keras.layers.UpSampling2D((2,2)))\n","  model.add(tf.keras.layers.UpSampling2D((2,2)))\n","  model.add(tf.keras.applications.ResNet50(\n","      include_top=False,\n","      weights='imagenet',\n","      input_shape=(256, 256, 3)\n","  ))\n","  model.add(tf.keras.layers.Flatten())\n","  model.add(tf.keras.layers.BatchNormalization())\n","  model.add(tf.keras.layers.Dense(128, activation='relu'))\n","  model.add(tf.keras.layers.Dropout(0.5))\n","  model.add(tf.keras.layers.BatchNormalization())\n","  model.add(tf.keras.layers.Dense(64, activation='relu'))\n","  model.add(tf.keras.layers.Dropout(0.5))\n","  model.add(tf.keras.layers.BatchNormalization())\n","  model.add(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax'))\n","\n","  return model"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"xi9-0Wh1V53F"},"source":["# load cifar10 dataset\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n","x_train = x_train / 255.0\n","x_test = x_test / 255.0\n","\n","# convert to one-hot vectors\n","y_train = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n","y_test = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n","\n","model = build_model()\n","model.build(input_shape=(None, 32, 32, 3))\n","model.summary()\n","\n","# set optimizer and compile model\n","opt_rms = tf.keras.optimizers.RMSprop(learning_rate=2e-5)\n","model.compile(optimizer=opt_rms, loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fLx_rUl_bYD6"},"source":["# training\n","start = time.time()\n","\n","print(\"\\tStart training [\", time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()), \"]\\n\")\n","train_history = model.fit(\n","    x_train, y_train,\n","    epochs=EPOCHS,\n","    batch_size=BATCH_SIZE_TRAIN,\n","    validation_data=(x_test, y_test),\n","    verbose=1)\n","print(\"\\n\\tEnd training [\", time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()), \"]\")\n","\n","end = time.time()\n","print(\"\\n\\tTotal training time:\", datetime.timedelta(seconds=round(end - start, 0)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c9X2HdORdhbZ"},"source":["# testing\n","scores = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE_TEST, verbose=1)\n","print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100, scores[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p23tEXoMdskM"},"source":["# save to disk\n","with open(f\"{CNN_NAME}_{EPOCHS}_model.json\", 'w') as model_file:\n","  model_file.write(model.to_json())\n","model.save_weights(f\"{CNN_NAME}_{EPOCHS}_weights.h5\")\n","\n","with open(f\"{CNN_NAME}_{EPOCHS}_history.sav\", 'wb') as history_file:\n","  pickle.dump(train_history.history, history_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xa-sfhCqdvwC"},"source":["# load history\n","history = pickle.load(open(f\"{CNN_NAME}_{EPOCHS}_history.sav\", \"rb\"))\n","\n","plt.figure(figsize=(15.0, 9.0))\n","plt.xlabel('Epoch')\n","\n","#plt.plot(history['loss'])\n","#plt.plot(history['val_loss'])\n","#plt.title('Custom CNN loss')\n","#plt.ylabel('Loss')\n","#plt.legend(['Train', 'Validation'], loc='upper center')\n","\n","plt.plot(history['accuracy'])\n","plt.plot(history['val_accuracy'])\n","plt.title('Custom CNN accuracy')\n","plt.ylabel('Accuracy')\n","plt.legend(['Train', 'Validation'], loc='lower center')\n","plt.xticks(np.arange(len(history['accuracy'])), np.arange(1, len(history['accuracy'])+1))\n","\n","plt.show()"],"execution_count":null,"outputs":[]}]}